{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RELIANCE</td>\n",
       "      <td>Reliance Industries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCS</td>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HDFCBANK</td>\n",
       "      <td>HDFC Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ICICIBANK</td>\n",
       "      <td>ICICI Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BHARTIARTL</td>\n",
       "      <td>Bharti Airtel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>LGBBROSLTD</td>\n",
       "      <td>LG Balakrishnan &amp; Bros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>NSIL</td>\n",
       "      <td>Nalwa Sons Investments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>CARERATING</td>\n",
       "      <td>CARE Ratings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>MEDIASSIST</td>\n",
       "      <td>Medi Assist Healthcare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>JSFB</td>\n",
       "      <td>Jana Small Finance Bank</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>820 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Symbol                       Name\n",
       "0      RELIANCE        Reliance Industries\n",
       "1           TCS  Tata Consultancy Services\n",
       "2      HDFCBANK                  HDFC Bank\n",
       "3     ICICIBANK                 ICICI Bank\n",
       "4    BHARTIARTL              Bharti Airtel\n",
       "..          ...                        ...\n",
       "815  LGBBROSLTD     LG Balakrishnan & Bros\n",
       "816        NSIL     Nalwa Sons Investments\n",
       "817  CARERATING               CARE Ratings\n",
       "818  MEDIASSIST     Medi Assist Healthcare\n",
       "819        JSFB    Jana Small Finance Bank\n",
       "\n",
       "[820 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "companies_list = pd.read_csv('symbols.csv')\n",
    "companies_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a BSE India session...\n",
      "\n",
      "Checking RELIANCE...\n",
      "Successfully found 11 PDFs for RELIANCE\n",
      "-#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#-\n",
      "Attempting PDF 1: https://www.bseindia.com/stockinfo/AnnPdfOpen.aspx?Pname=aa0547ba-09ef-404d-b57d-c216d1513f17.pdf\n",
      "‚úÖ Successfully saved: screener_pdfs/RELIANCE_concall_1.pdf\n",
      "Attempting PDF 2: https://www.bseindia.com/stockinfo/AnnPdfOpen.aspx?Pname=89c33a3e-5683-4a1d-b8f9-1952ff4df63f.pdf\n",
      "‚úÖ Successfully saved: screener_pdfs/RELIANCE_concall_2.pdf\n",
      "Attempting PDF 3: https://www.bseindia.com/stockinfo/AnnPdfOpen.aspx?Pname=0e6309fa-450f-4db6-88b2-d76d9a3ff756.pdf\n",
      "‚úÖ Successfully saved: screener_pdfs/RELIANCE_concall_3.pdf\n",
      "Attempting PDF 4: https://www.bseindia.com/stockinfo/AnnPdfOpen.aspx?Pname=191e6ab9-4751-4017-ba5f-bb63daf2d871.pdf\n",
      "‚úÖ Successfully saved: screener_pdfs/RELIANCE_concall_4.pdf\n",
      "Attempting PDF 5: https://www.bseindia.com/stockinfo/AnnPdfOpen.aspx?Pname=06b05d06-8c38-4aee-aa5b-5e7108ae3871.pdf\n",
      "‚úÖ Successfully saved: screener_pdfs/RELIANCE_concall_5.pdf\n",
      "Attempting PDF 6: https://www.bseindia.com/stockinfo/AnnPdfOpen.aspx?Pname=de3e8ff3-efca-4266-9bc8-7509f48574a4.pdf\n",
      "‚úÖ Successfully saved: screener_pdfs/RELIANCE_concall_6.pdf\n",
      "Attempting PDF 7: https://www.bseindia.com/stockinfo/AnnPdfOpen.aspx?Pname=ef9baa21-923a-48ad-9fb7-2157af59ae16.pdf\n",
      "‚úÖ Successfully saved: screener_pdfs/RELIANCE_concall_7.pdf\n",
      "Attempting PDF 8: https://www.bseindia.com/stockinfo/AnnPdfOpen.aspx?Pname=f2fa506f-675b-46db-9f7b-26303a05d6b9.pdf\n",
      "‚úÖ Successfully saved: screener_pdfs/RELIANCE_concall_8.pdf\n",
      "Attempting PDF 9: https://www.bseindia.com/stockinfo/AnnPdfOpen.aspx?Pname=9c8c3f07-883a-476b-8fb2-8fe74078e9f5.pdf\n",
      "‚úÖ Successfully saved: screener_pdfs/RELIANCE_concall_9.pdf\n",
      "Attempting PDF 10: https://www.bseindia.com/stockinfo/AnnPdfOpen.aspx?Pname=dfb275bd-fd47-4a38-964e-21a67e26b3c2.pdf\n",
      "‚úÖ Successfully saved: screener_pdfs/RELIANCE_concall_10.pdf\n",
      "Attempting PDF 11: https://www.bseindia.com/stockinfo/AnnPdfOpen.aspx?Pname=aa7a60c6-791d-4e59-94e6-9f94c3a506fc.pdf\n",
      "‚úÖ Successfully saved: screener_pdfs/RELIANCE_concall_11.pdf\n",
      "\n",
      "üèÅ Done\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "\n",
    "companies = ['RELIANCE']\n",
    "\n",
    "if not os.path.exists('screener_pdfs'):\n",
    "    os.mkdir('screener_pdfs')\n",
    "\n",
    "# This configuration is necessary for creating a session with bse\n",
    "session = requests.Session()\n",
    "session.headers.update({\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "    'Accept-Language': 'en-US,en;q=0.5',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Referer': 'https://www.bseindia.com/',\n",
    "    'DNT': '1',\n",
    "    'Upgrade-Insecure-Requests': '1'\n",
    "})\n",
    "\n",
    "print(\"Creating a BSE India session...\")\n",
    "session.get(\"https://www.bseindia.com/\")\n",
    "\n",
    "for company in companies:\n",
    "    print(f\"\\nChecking {company}...\")\n",
    "    url = f'https://www.screener.in/company/{company}/consolidated/'\n",
    "    \n",
    "    try:\n",
    "        page = session.get(url)\n",
    "        page.raise_for_status()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Page load failed: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    pdf_links = soup.find_all('a', class_='concall-link', title=\"Raw Transcript\")\n",
    "    \n",
    "    if not pdf_links:\n",
    "        print(f\"No PDF links found for {company}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Successfully found {len(pdf_links)} PDFs for {company}\")\n",
    "    print(f\"{'-#-'*30}\")\n",
    "    \n",
    "    for i, link in enumerate(pdf_links, 1):\n",
    "        pdf_url = link['href']\n",
    "        print(f\"Attempting PDF {i}: {pdf_url}\")\n",
    "        \n",
    "        if not pdf_url.endswith('.pdf'):\n",
    "            print(\"Skipping non-PDF link\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Add BSE-specific headers\n",
    "            headers = {\n",
    "                'Origin': 'https://www.bseindia.com',\n",
    "                'Sec-Fetch-Dest': 'document',\n",
    "                'Sec-Fetch-Mode': 'navigate',\n",
    "                'Sec-Fetch-Site': 'same-origin'\n",
    "            }\n",
    "            \n",
    "            response = session.get(pdf_url, headers=headers, timeout=10)\n",
    "            \n",
    "            # Verify successful response\n",
    "            if response.status_code != 200:\n",
    "                print(f\"Failed with status code: {response.status_code}\")\n",
    "                continue\n",
    "                \n",
    "            if 'application/pdf' not in response.headers.get('Content-Type', ''):\n",
    "                print(\"Response is not a PDF\")\n",
    "                continue\n",
    "                \n",
    "            # Generate filename\n",
    "            filename = f\"screener_pdfs/{company}_concall_{i}.pdf\"\n",
    "            \n",
    "            # Save PDF\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "                \n",
    "            print(f\"‚úÖ Successfully saved: {filename}\")\n",
    "            \n",
    "            # Add delay to avoid rate limiting\n",
    "            time.sleep(1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Download failed: {str(e)}\")\n",
    "\n",
    "print(\"\\nüèÅ Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "\n",
    "def extract_dialogues_from_pdf(pdf_path, top_margin=70, bottom_margin=100, left_margin=30, right_margin=30):\n",
    "    \"\"\"\n",
    "    Extract dialogues from a PDF, excluding headers and footers by cropping pages. This function also skips the first\n",
    "    page and handles overlapping text at page breaks.\n",
    "\n",
    "    Args:\n",
    "    pdf_path (str): Path to the PDF file.\n",
    "    top_margin (int): Number of points to exclude from the top of each page.\n",
    "    bottom_margin (int): Number of points to exclude from the bottom of each page.\n",
    "    left_margin (int): Number of points to exclude from the left of each page.\n",
    "    right_margin (int): Number of points to exclude from the right of each page.\n",
    "\n",
    "    Returns:\n",
    "    str: A string containing all extracted dialogues, formatted as \"Speaker: Dialogue\".\n",
    "    \"\"\"\n",
    "    # More lenient regex to capture speaker names including initials or single names\n",
    "    speaker_pattern = re.compile(r'^([A-Z][a-zA-Z.]+(?: [A-Z][a-zA-Z.]+)*):')\n",
    "\n",
    "    all_dialogues = \"\"\n",
    "    buffer_text = \"\"  # Buffer to hold the last line of the previous page\n",
    "    current_dialogue = \"\"\n",
    "    current_speaker = None\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        # Skip the first page\n",
    "        for page in pdf.pages[1:]:\n",
    "            page_width, page_height = page.width, page.height\n",
    "\n",
    "            # Define the bounding box to crop the page\n",
    "            bbox = (left_margin, bottom_margin, page_width - right_margin, page_height - top_margin)\n",
    "            cropped_page = page.crop(bbox)\n",
    "            page_text = cropped_page.extract_text() or \"\"\n",
    "\n",
    "            # Combine the text from the buffer and the current page\n",
    "            combined_text = buffer_text + \"\\n\" + page_text\n",
    "            lines = combined_text.split(\"\\n\")\n",
    "\n",
    "            # Handle potential duplicate lines at the start of the new page\n",
    "            if lines and lines[0].strip() == buffer_text.strip():\n",
    "                lines = lines[1:]\n",
    "\n",
    "            # Process each line to extract speaker and dialogue\n",
    "            for line in lines:\n",
    "                speaker_match = speaker_pattern.match(line.strip())\n",
    "                if speaker_match:\n",
    "                    if current_speaker:\n",
    "                        all_dialogues += f\"{current_speaker}: {current_dialogue.strip()}\\n\"\n",
    "                    current_speaker = speaker_match.group(1)\n",
    "                    current_dialogue = line[speaker_match.end():].strip()\n",
    "                else:\n",
    "                    current_dialogue += \" \" + line.strip()\n",
    "\n",
    "            # Update the buffer with the last line of the current page\n",
    "            buffer_text = lines[-1] if lines else \"\"\n",
    "\n",
    "        # Include the final speaker's dialogue if any remains\n",
    "        if current_speaker and current_dialogue.strip():\n",
    "            all_dialogues += f\"{current_speaker}: {current_dialogue.strip()}\\n\"\n",
    "\n",
    "    return all_dialogues\n",
    "\n",
    "# Specify the PDF path and extract dialogues\n",
    "pdf_path = \"screener_pdfs/RELIANCE_concall_1.pdf\"\n",
    "extracted_dialogues = extract_dialogues_from_pdf(\n",
    "    pdf_path,\n",
    "    top_margin=70,\n",
    "    bottom_margin=100,\n",
    "    left_margin=30,\n",
    "    right_margin=30\n",
    ")\n",
    "print(extracted_dialogues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dialogue_chunks(extracted_text):\n",
    "    \"\"\"\n",
    "    Converts extracted dialogue text into a list of structured dictionaries, each representing a chunk of dialogue.\n",
    "\n",
    "    Args:\n",
    "    extracted_text (str): Extracted dialogues as a single string.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of dictionaries, each containing a chunk_id, speaker, and text.\n",
    "    \"\"\"\n",
    "    lines = extracted_text.strip().split(\"\\n\")\n",
    "    chunks = []\n",
    "\n",
    "    for i, line in enumerate(lines, start=1):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue  # Skip any empty lines\n",
    "\n",
    "        # Attempt to split each line into speaker and dialogue\n",
    "        parts = line.split(\":\", 1)\n",
    "        if len(parts) == 2:\n",
    "            speaker, dialogue_text = parts\n",
    "            speaker = speaker.strip()\n",
    "            dialogue_text = dialogue_text.strip()\n",
    "\n",
    "            # Store each dialogue as a dictionary\n",
    "            chunk = {\n",
    "                \"chunk_id\": i,\n",
    "                \"speaker\": speaker,\n",
    "                \"text\": dialogue_text\n",
    "            }\n",
    "            chunks.append(chunk)\n",
    "        else:\n",
    "            # Handle lines that don't conform to the expected format\n",
    "            continue  # Optionally add error handling or logging here\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Create chunks from the extracted dialogues\n",
    "chunks = create_dialogue_chunks(extracted_dialogues)\n",
    "\n",
    "# Print each chunk in a readable format\n",
    "for chunk in chunks:\n",
    "    print(f\"Chunk ID: {chunk['chunk_id']}\")\n",
    "    print(f\"Speaker: {chunk['speaker']}\")\n",
    "    print(f\"Text: {chunk['text']}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
